# Memory Management

## 메모리 계층 구조

![memory hierarchy](https://user-images.githubusercontent.com/57662010/194758429-156502d2-21a2-404c-8bdc-02420d7ba1db.JPG)

**메모리 계층 구조(memory hierarchy)**는 서로 다른 특성 메모리들을 계층 구조로 구성한 것이다. 레지스터, 캐시, 메인 메모리는 휘발성으로 전원이 끊기면 기록된 데이터가 모두 날라간다. 또한 CPU가 직접 접근할 수 있다. 디스크와 테이프는 비휘발성으로 전원이 공급되지 않아도 그 내용이 지워지지 않는다. CPU는 이들에 직접 접근할 수 없고 컨트롤러 등을 통하여 접근할 수 있다. 비휘발성 메모리는 휘발성 메모리에 비하여 그 크기가 매우 크지만 느리다. 휘발성 메모리는 비휘발성 메모리에 비하여 성능이 좋지만 크기가 매우 작으며 비싸다.

운영체제는 디스크로부터 실행할 프로세스의 코드와 데이터를 가져와 메인 메모리에 적재한다. CPU는 메모리로부터 데이터와 명령어를 가져와 레지스터에 적재하고 실행한다. 이때 메인 메모리에 접근하는 속도가 CPU에 비해 현저히 느리므로 중간에 고속의 캐시를 두어 성능 저하를 막는다.



## 메인 메모리

**메인 메모리(main memory)**는 CPU가 직접 접근할 수 있는 기억장치로 실행할 프로세스를 적재한다. 프로세스는 실행되기 위해 메모리에 적재되어야한다.



## 캐시

**캐시(cache)**는 CPU 내부에 있는 고속의 기억장치로, CPU와 메모리의 속도 차이로 발생하는 성능 저하를 해결한다. 메모리에서 가져온 데이터를 캐시에 저장하여 CPU는 캐시부터 탐색한 후 원하는 데이터가 없으면 메인 메모리를 탐색한다. 원하는 데이터가 캐시에 있다면 **캐시 적중(hit)**이라고 한다.

### 지역성

캐시가 적중하지 않는다면 메모리에 접근하는 시간과 캐시에 접근하는 시간이 들어 기존 방식보다 오래 걸린다. 하지만 참조 지역성 때문에 일반적으로 캐시 적중률은 준수하다. **참조 지역성(Locality of Reference)**은 참조되었던 데이터나 관계가 있는 데이터가 가까운 미래에 다시 참조될 가능성이 높은 특성을 가리킨다. 참조 지역성에는 세 가지가 있다.

첫번째, **시간 지역성(temporal locality)**이다. 한 번 참조한 데이터는 다시 참조할 가능성이 높다는 뜻이다. 두번째, **공간 지역성(spatial locality)**이다. 참조된 데이터에 인접한 데이터를 미래에 참조할 가능성이 높다는 뜻이다. 세번째, **순차적 지역성(sequential locality)**이다. 데이터가 순차적으로 참조될 가능성이 높다는 뜻으로, 공간 지역성의 특별한 경우로 보기도 한다.

### 캐시 사상 기법

CPU는 워드 단위로 데이터를 가져오나, 캐시는 공간 지역성에 따라 인접한 데이터와 함께 블록 단위로 저장한다. 캐시 라인은 태그와 데이터로 구성된다. 캐시 사상(Cache Mapping) 기법은 메인 메모리의 데이터를 캐시 메모리의 어느 위치에 저장할 것인지 결정하는 방법이다.

첫번째, **완전 연관 사상(Fully Associative Mapping)**이다. 캐시 라인마다 비교 회로가 있으며 태그는 메인 메모리를 가리키는 주소를 저장한다. 이때 메인 메모리의 데이터는 캐시 메모리의 어느 위치에나 저장될 수 있다.  이 방식에서는 각각의 비교회로로 태그가 원하는 메모리 주소와 일치하는지 비교한다. 비교회로가 많아 성능은 매우 좋지만 같은 이유로 비싸다.

두번째, **직접 연관 사상(Direct Associative Mapping)**이다. 각 캐시 라인마다 인덱스가 있으며 비교 회로는 하나이다. 인덱스는 메모리 주소의 뒷부분을 가리키며, 남은 주소가 태그에 저장된다. 이때 메인 메모리의 데이터는 주소 뒷부분이 일치하는 인덱스의 라인에만 저장될 수 있다. 이 방식에서는 원하는 메모리의 주소 뒷부분을 인덱스로 해당하는 라인에 접근한다. 그리고 비교회로가 해당 라인의 태그가 남은 주소와 일치하는지 비교한다. 비교회로가 하나이므로 가격이 싸지만, 같은 이유로 성능이 좋지 않다.

세번째, **집합 연관 사상(Set Associative Mapping)**이다. 각 캐시 라인은 두 개의 태그-데이터 쌍을 가지며 비교 회로도 두 개 이다. 인덱스로 라인에 접근한 후 각각의 비교 회로가 태그를 비교하여 원하는 메모리의 주소와 일치하는지 비교한다. 완전 연관 사상과 직접 연관 사상에 대해 중간 정도의 성능을 제공한다.

### 캐시 쓰기 정책

**캐시 쓰기 정책(cache write policy)**은 캐시 메모리의 변경 사항을 언제 메모리에 반영할 것인지 결정한다. **write-through**은 캐시와 메모리를 동시에 갱신한다. CPU가 메모리 쓰기를 기다리므로 비효율적이다. **write-back**은 캐시에만 반영한 후 캐시 라인이 교체될 때에 메모리에 반영한다. 캐시와 메모리의 데이터가 일치하지 않는 문제가 있다.

wrtie miss(캐시에 적재되지 않은 위치에 쓰기)가 발생하면 캐시에 이 데이터를 적재할 것인지 결정해야한다. **write-alloction**은 메모리로부터 데이터를 읽어 캐시에 적재한 후 캐시에 변경 사항을 반영한다. 일반적으로 write-back과 함께 사용한다. **write-around**는 메인 메모리에만 변경 사항을 반영한다. 데이터가 다시 사용되지 않을 때 사용하는 것이 좋다.

### 캐시 교체 정책

**캐시 교체 정책(cache replacement policy)**는 캐시가 꽉 찼을 때 어떤 캐시 블록을 비울 것인지 결정한다. **FIFO(First In First Out)**은 적재된 지 가장 오래된 캐시 블록을 비운다. **LRU(Least Recently Used)**는 참조된 지 가장 오래된 캐시 블록을 비운다. 간단하지만 참조된 시점을 기록해야한다. **LFU(Least Frequency Used)**는 가장 적게 참조된 캐시 블록을 비운다. 참조된 횟수를 기록해야한다.



## 프로그램 실행 과정

C언어로 작성된 프로그램 코드가 디스크에 적재되어있다고 하자.

1. 전처리(preprocessing): 전처리기(preprocessor)가 전처리문을 실행하여 다른 코드로 변환한다.
2. 컴파일(compilation): 컴파일러(compiler)가 코드를 어셈블리어로 작성된 어셈블리 코드로 변환한다.
3. 어셈블(assembling): 어셈블러(assembler)가 어셈블리 코드를 0과 1로 이루어진 오브젝트 코드로 변환한다.
4. 링크(linking): 링커(linker)가 여러 개의 오브젝트 코드(라이브러리와 소스 코드)를 하나로 합쳐 실행 가능한 파일(executable file, 실행 파일)로 변환한다. 실행 파일에는 실행 가능한 코드(executable code)와 읽기 전용 상수를 저장한 텍스트 섹션과 전역 데이터를 저장한 데이터 섹션이 있다.
   1. 정적 링킹(static linking): 프로세스 실행 전 모든 라이브러리 코드까지 하나로 합쳐 실행 파일을 만드는 방식
   2. 동적 링킹(dynamic linking): 프로세스를 실행하며 그때마다 필요한 라이브러리를 메모리에 적재하는 방식. 프로세스들이 라이브러리 코드를 공유할 수 있다.
5. 로딩(loading): 로더(loader)가 프로세스에게 할당된 메모리에 실행 파일을 복사한다. 이때 메모리에 적재된 프로세스의 주소 공간을 프로세스의 수행 이미지(process image)라고 한다.
   1. 정적 로딩(static loading): 프로세스 실행 전 수행 이미지 전체를 메모리에 적재하는 방식
   2. 동적 로딩(dynamic loading): 프로세스를 실행하며 그때마다 필요한 수행 이미지 일부를 메모리에 적재하는 방식. 다중 프로그래밍 환경에서 효율성을 높일 수 있다.
6. 실행(execution): CPU가 메모리에서 데이터를 읽어 레지스터에 적재하고 실행한다.



## 재배치

**재배치(relocation)**은 디스크에서 데이터를 읽어 메모리에 적재하는 과정이다. 이때 논리 주소를 물리 주소로 변환하는 과정을 주소 바인딩(address binding)이라고 한다. 재배치는 주소 바인딩 시점에 따라 정적 재배치와 동적 재배치로 나눌 수 있다.

**정적 재배치(static relocation)**는 로드 타임 바인딩(load time binding)을 사용한다. 로드 타임 바인딩은 프로세스가 메모리에 적재될 때 프로그램이 참조하고 있는 모든 주소를 수정하는 것을 의미한다. 이 방식은 프로그램의 내용을 수정하므로 적재하는 시간을 증가시키며, 명령어의 오퍼랜드가 데이터인지 아니면 데이터의 주소인지 구분할 수 있어야 한다. 또한 모든 주소를 확정해야하므로 프로세스는 연속된 공간에 저장되며 위치를 옮기기 어렵다.

**동적 재배치(dynamic relocation)**는 런타임 바인딩(execution time/runtime binding)을 사용한다. 런타임 바인딩은 프로세스를 실행하면서 메모리에 접근할 때마다 논리 주소를 물리 주소로 주소 변환하는 것을 의미한다. 이 방식은 프로그램의 내용을 수정하지 않으며, 프로세스는 메모리에 연속적으로 저장되거나 그러지 않을 수 있다. 현대의 운영체제는 동적 재배치를 사용한다.



## MMU

메모리 관리자(memory manager)는 CPU가 프로세스를 실행하기 위해 메모리에 접근하는 것을 관리한다. 메모리 관리자의 역할은 **MMU(Memory Management Unit)**라는 하드웨어가 담당한다.

MMU가 하는 일은 대표적으로 다음과 같다. 첫번째, 프로세스를 실행하기 위해 필요한 코드와 데이터를 가져와 메모리에 적재한다. 두번째, 프로그램을 실행하며 동적으로 논리 주소를(가상 메모리 시스템에서는 가상 주소를) 물리 주소로 변환한다. 세번째, 프로세스가 필요로 할 때 메모리를 할당해주고 사용하지 않는다면 해제한다. 네번째, 메모리를 보호한다. 메모리 보호란 각각의 프로세스가 독립적인 주소 공간을 유지할 수 있도록 현재 프로세스가 다른 프로세스의 주소 공간에 접근하는 것을 막거나, 악의나 버그가 있는 프로세스가 금지된 주소 공간에 접근하지 않게 막는 것이다. 다섯번째, 캐시를 관리한다. 여섯번째, 버스를 중재한다.

### 메모리 보호하기

동적 재배치를 사용하며 프로세스가 메모리에 연속으로 저장되는 경우 **base(relocation)와 limit 하드웨어 레지스터**를 사용하여 메모리를 보호할 수 있다. base 레지스터는 메모리에 적재된 프로그램의 시작 주소를 저장하며 limit 레지스터는 프로그램의 크기를 저장한다. 이때 프로세스의 유효 주소 공간의 범위는 `base 레지스터의 값 <= 유효 주소 < base 레지스터의 값 + limit 레지스터의 값`와 같다. CPU는 프로세스가 메모리를 참조할 때마다 참조하려는 메모리의 주소에 base 레지스터의 값을 더하여 유효 주소 공간의 범위에 속하는지 확인한다. 유효하다면 메모리 버스에 변환한 주소를 실어 보내고, 그렇지 않다면 메모리 참조를 중단하고 트랩을 발생시켜 프로세스를 강제 종료한다.



## 메모리 단편화

**메모리 단편화(memory fragmentation)**란 메모리에 빈 공간이 충분함에도 사용할 수 없는 문제를 가리킨다. 단편화는 내부 단편화와 외부 단편화로 나눌 수 있다.

**내부 단편화(internal fragmentation)**란 프로세스에게 필요로 하는 것보다 더 많은 메모리가 할당되어 공간이 낭비되는 문제이다. **외부 단편화(external fragmentation)**는 빈 공간의 크기가 프로세스에게 연속적인 메모리를 할당하기에는 충분하지 않아 낭비되는 문제이다.

### 외부 단편화 해결하기

할당하지 않은 공간들이 연속되도록 합치면 외부 단편화를 해결할 수 있다. 첫번째, 프로세스가 종료되어 메모리를 반납할 때 이 메모리를 인접한 빈 공간과 병합(coalescing)한다. 두번째, 주기적으로 모든 빈 공간을 모아 합친다. 압축(compaction)이라고 한다. 모든 빈 공간이 하나로 합쳐진다는 점에서 병합보다 이상적이다. 그러나 최적의 압축 알고리즘을 찾기 힘들다. 또한 메모리를 동적으로 재배치하고 시스템의 활동을 정지시켜야해서 오버헤드가 상당히 크다.



## 메모리 할당

오늘날의 멀티 프로그래밍에서 CPU는 여러 개의 프로세스를 번갈아가며 실행한다. 프로세스는 운영체제로부터 할당받은 메모리에 적재되어 실행되므로, 운영체제는 메모리를 적절한 크기로 분할하여 다수의 프로세스들에게 할당할 수 있어야 한다.

메모리를 할당하는 방식은 연속 할당 방식과 불연속 할당 방식으로 나눌 수 있다.

### 연속 할당 방식

**연속 할당 방식(contiguous allocation)**은 물리적 메모리를 분할하고 각 분할마다 하나의 프로세스를 배치한다. 연속할당 방식은 분할의 크기에 따라 고정 분할 방식과 가변 분할 방식으로 나눌 수 있다.

**고정 분할(fixed partition allocation) 방식**은 고정된 크기의 분할에 프로세스를 배치하는 연속 할당 방식이다. 내부 단편화와 외부 단편화가 발생할 수 있다. **가변 분할(variable parition allocation) 방식**은 프로세스의 크기만큼의 분할에 프로세스를 배치하는 연속 할당 방식이다. 내부 단편화는 발생하지 않으나 외부 단편화가 발생할 수 있다.

#### 메모리 배치 알고리즘

**메모리 배치 알고리즘**은 프로세스에게 가변 분할 방식의 연속 메모리를 할당할 때 빈 공간을 선택하는 알고리즘이다.

첫번째, **최초적합(first-fit) 알고리즘**이다. 위에서부터 탐색하다가 필요한 것보다 큰 공간을 발견하면 들어간다. 빠르지만, 위에서부터 탐색하므로 사용되지 않는 아래 쪽의 메모리가 낭비되는 단점이 있다.

두번째, **최적적합(best-fit) 알고리즘**이다. 전체 공간을 탐색하여 필요한 것보다 큰 공간 중 가장 작은 공간에 들어간다. 외부 단편화의 크기를 줄일 수 있지만, 느리고 작은 외부 단편화가 여러 개 생긴다는 단점이 있다.

세번째, **최악적합(worst-fit) 알고리즘**이다. 전체 공간을 탐색하여 가장 큰 공간에 들어간다. 빈 공간의 크기가 작지 않아 다시 사용할 수도 있지만, 느리다는 단점이 있다.

네번째, **다음적합(next-fit) 알고리즘**이다. 이전 검색 위치부터 탐색하여 첫번째로 발견한 적재 가능한 공간에 들어간다. 전체 공간을 골고루 사용하지만, 골고루 작은 외부 단편화가 생긴다는 단점이 있다. 

### 불연속 할당 방식

**불연속 할당 방식(noncontiguous allocation)**는 프로세스를 물리적 메모리에 분산 배치한다. 불연속 할당 방식은 분할의 크기에 따라 페이징 기법과 세그멘테이션 기법으로 나눌 수 있다.

**페이징(paging) 기법**은 주소 공간을 고정된 크기의 페이지로 자르고 페이지 단위로 적재하는 방식이다. **세그멘테이션(segmentation) 기법**은 주소 공간을 의미 있는 가변 크기의 세그먼트로 자르고 세그먼트 단위로 적재하는 방식이다.



## 멀티 프로그래밍에서의 메모리 관리 기법

오늘날의 멀티 프로그래밍에서 CPU는 여러 개의 프로세스를 번갈아가며 실행한다. 프로세스는 운영체제로부터 할당받은 메모리에 적재되어 실행되는데, 실제 RAM의 용량은 모든 프로세스들이 필요로 하는 메모리의 총 크기보다 작다. 이 문제를 해결하기 위해 메모리 관리 기법으로 연속 할당 방식의 스와핑과 불연속 할당 방식의 가상 메모리을 사용해보자.

### 스와핑

**스와핑(swapping)**은 한 프로세스의 전체 수행 이미지를 연속적인 메모리에 적재하여 실행하다가, 실행되지 않으면 하드디스크의 스왑 영역(swap space)로 내보내는(swap out) 기법이다. 스왑 영역의 프로세스는 다시 실행되면 스왑 영역에서 메모리로 올려진다(swap in).

스와핑의 단점은 외부 단편화가 생긴다는 것이다. 또한 메모리가 꽉 찼을 때 실행 중인 프로세스의 크기가 증가한다면 실행 중이던 다른 프로세스를 스왑 영역으로 보내야하는데, 스왑 영역마저 꽉 차 있으면 증가하려는 프로세스를 중단(suspend)시키거나 강제로 종료(kill)시켜야 한다. 이 문제를 해결하려면 프로세스가 실행 중에 증가할 것을 예상하여 메모리에 적재할 때 여분의 공간을 제공해주어야한다.

### 가상 메모리

가상 메모리는 불연속 할당 방식을 사용한다.

스와핑 기법은 결국 물리 메모리 크기에 의해 많은 제약을 가진다. 물리 메모리의 크기에 제약받지 않는 방법은 없을까?

[가상 메모리](https://github.com/leegwae/operating-system/blob/main/Virtual%20Memory.md) 참고



## 참고

- 운영체제 강의 필기
- 운영체제론(노상혁, 이동희, 천홍석, 최동우 공역) 3장 메모리 관리
- 컴퓨터구조론 강의 필기
- 컴퓨터구조론 개정 5판(김종현 저) 1장 컴퓨터시스템 개요, 5장 기억장치
- 운영체제와 정보기술의 원리 - 7장 메모리 관리
- [위키백과 - 메모리 관리 장치](https://ko.wikipedia.org/wiki/%EB%A9%94%EB%AA%A8%EB%A6%AC_%EA%B4%80%EB%A6%AC_%EC%9E%A5%EC%B9%98)
- [위키백과 - Relocation](https://en.wikipedia.org/wiki/Relocation_(computing))
- [geeksforgeeks - Address Binding and its Types](https://www.geeksforgeeks.org/address-binding-and-its-types/)
- [geeksforgeeks - Write Through and Write Back in Cache](https://www.geeksforgeeks.org/write-through-and-write-back-in-cache/)
- [BUFFER OVERFLOW 4 A Compiler, Assembler, Linker & Loader](https://www.tenouk.com/Bufferoverflowc/Bufferoverflow1c.html)



## 스터디

### 캐시는 왜 사용하는가?

메인 메모리 작업 속도가 CPU의 작업 속도에 비해 많이 느리기 때문이다. CPU 내부에 캐시를 두어 성능 저하를 막는다.

### 캐시 교체 알고리즘에는 무엇이 있는가?

FIFO(First In First Out)은 적재된 지 가장 오래된 캐시 블록을 비운다. LRU(Least Recently Used)는 참조된 지 가장 오래된 캐시 블록을 비운다. LFU(Least Frequency Used)는 가장 적게 참조된 캐시 블록을 비운다.

### LRU 캐시는 어떻게 구현할 수 있을까요?

캐시를 해시맵으로 구현한다고 가정하겠다. 각 블록마다 참조된 시점을 기록한다. 블록에 접근할 때마다 참조된 시점을 저장한 필드를 업데이트하겠다. 캐시가 꽉 차면 이 필드로 참조한 지 가장 오래된 블록을 찾아 비우겠다. 

### C 언어로 작성된 프로그램 코드가 디스크에 적재되어있다. 이 코드가 실행되기까지의 과정을 서술하라.
전처리(전처리기-소스 코드의 전처리문을 다른 코드로 변환), 컴파일(컴파일러-소스코드를 어셈블리 코드로 변환), 어셈블링(어셈블러-어셈블리 코드를 오브젝트 코드로 변환), 링킹(링커-라이브러리 코드까지 가져와서 실행 파일 만듦), 로딩(로더-할당된 메모리에 실행 파일 복사하여 이미지 만듦), 실행(CPU가 메모리에서 데이터 읽어와 실행)

### MMU는 어떤 역할을 하는가?

MMU(Memory Management Unit)은 CPU가 프로세스를 실행하기 위해 메모리에 접근하는 것을 관리한다. 동적으로 논리 주소를 물리 주소로 변환하거나 프로세스가 독립적인 주소 공간을 유지하도록 메모리를 보호한다.

### MMU는 어떻게 메모리를 보호하는가?

프로세스를 연속적인 메모리에 배치한다고 하자. base 레지스터가 프로세스의 시작 주소를, limit 레지스터가 프로세스의 크기를 저장한다. CPU가 접근하려는 메모리의 주소가 base 레지스터의 값보다 같거나 크고, limit과 base를 더한 값보다 작으면 유효한 주소이다. 해당 주소 범위를 넘으면 trap을 발생시켜 프로세스를 종료시킨다.

### 단편화란 무엇인가?

### 메모리에 프로세스 전체 이미지를 올릴 수 없는 경우 어떻게 해결할 수 있는가?

기존에 수행 중이던 프로세스의 이미지를 내려 공간을 확보하겠다.

### 메모리가 프로세스 전체 이미지보다 크기가 작으면 어떻게 해결할 수 있는가?

당장 프로세스를 실행하기 위해 필요한 프로세스 이미지 일부만 메모리에 올리겠다.

### 단편화란 무엇인가요?

단편화는 메모리에는 빈 공간에 충분하나 프로세스에게 할당할 수 없는 문제를 말한다. 내부 단편화는 프로세스에게 너무 큰 공간을 할당하여 남은 공간이 낭비되는 경우이다. 외부 단편화는 프로세스에게 연속적인 공간을 할당할 수 없는 경우이다.

### 외부 단편화는 어떻게 해결할 수 있을까?

주기적으로 모든 빈 공간을 하나로 모으거나 인접한 빈 공간을 합쳐 큰 빈 공간을 만든다.

### 메모리 할당 방식을 설명하라

메모리 할당 방식은 연속 할당 방식과 불연속 할당 방식으로 나눌 수 있다.

### 스와핑은 무엇이고 단점은 무엇인가?

스와핑은 프로세스의 전체 이미지를 메모리에 적재하여 실행하다가 실행되지 않거나 메모리 공간이 부족해지면 디스크의 SWAP 영역으로 swap out하는 메모리 관리 기법이다.

스와핑의 단점은 첫번째 외부 단편화가 생긴다는 것이고 두번째, 물리 메모리의 실제 크기에 영향을 받는다는 것이다.
