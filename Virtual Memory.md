# Virtual Memory

## 가상 메모리와 가상 주소 공간

**가상 메모리(virtual memory)** 기법에서 프로세스는 무한한 크기의 가상 메모리와 CPU 자원을 독점하고 있다는 환상을 가진다. 프로그램이 참조하는 주소는 가상 주소(virtual address)로, 프로세스의 가상 주소 공간(virtual address space)은 가상 메모리 공간 전체이다. 가상 주소 공간의 0번지부터 프로세스의 주소 공간, 라이브러리의 주소 공간, 커널의 주소 공간이 순서대로 할당되어 있다. 가상 메모리 기법은 프로세스의 전체 수행 이미지를 적재하는 스와핑과 달리 필요한 일부만 적재하여 실행한다.

가상 메모리 관리 기법에는 요구 페이징 기법과 요구 세그먼테이션 기법이 있다.



## 요구 페이징

**요구 페이징(paging)** 기법은 페이징 기법을 사용하는 가상 메모리 관리 기법이다. 가상 메모리는 고정된 크기로 나누어지는데 이 단위를 **페이지(page)**라고 하며, 물리 메모리에서 페이지와 동일한 크기의 **페이지 프레임(page frame)**이 페이지에 대응하게 된다.



## 가상 주소

**가상 주소(virtual address)**는 가상 메모리의 페이지를 가리키는 `페이지 번호`와 어디서부터 읽어야하는지 나타내는 `바이트 오프셋`으로 이루어진다. 이 주소로는 가상 메모리의 페이지에 대응하는 물리 메모리의 프레임에 접근할 수 없다. 따라서 가상 주소를 물리 주소로 변환해주어야 한다. 

MMU(Memory Management Unit)가 페이지 테이블(page table)을 사용하여 가상 주소를 물리 주소로 변환해주는데, 이것을 **동적 주소 변환(DAT; Dynamic Address Translation)**이라고 한다. 



## 페이지 테이블로 동적 주소 변환하기

**페이지 테이블(Page Table, Page Mapping Table)**은 인덱스로 페이지 번호를 사용하며 인덱스에 대응하는 페이지 테이블 엔트리에 페이지 프레임 번호(PFN; Page Frame Number)를 기록한다. 가상 주소 공간의 모든 페이지에 대하여 엔트리를 유지하므로 테이블의 크기는 가상 주소 공간의 크기에 따라 증가한다. 프로세스마다 페이지 테이블을 가지며, 페이지 테이블은 프로세스 상태의 일부이다. 기본적으로 페이지 테이블은 모두 DRAM에 기록된다.

페이지 테이블을 통한 동적 주소 변환 과정은 다음과 같다.

1. 가상 주소를 `페이지 번호`와 `바이트 오프셋`으로 구분한다.
2. 페이지 테이블에서 인덱스가 `페이지 번호`인 곳을 찾아 대응하는 엔트리에서 `프레임 번호`를 찾는다.
3. `프레임 번호`에 `바이트 오프셋`을 더하여 물리 주소로 변환한다.

### 페이지 테이블 엔트리

![image](https://user-images.githubusercontent.com/57662010/194643710-4dcd889e-2730-4190-85ce-2d2907a0a1aa.png)

**페이지 테이블 엔트리(PTE; Page Table Entry)**는 일반적으로 32비트 크기를 가지며, 페이지 프레임 번호 외에도 플래그들로 이루어져있다. 플래그의 종류는 CPU마다 다르며 일반적으로는 다음과 같다.

1. **present/absent 비트**(resident bit, valid/invalid bit): `1`이면 페이지가 프레임(메모리)에 적재되어 있으며(SWAP in) 기록된 프레임 번호가 유효하다는 것을 의미한다. `0`이면 페이지가 하드디스크의 SWAP 영역에 있으며(SWAP out) 이 프레임 번호 대신 디스크 주소가 기록되어있다는 것을 의미한다.
2. 보호 비트(protection bit): 페이지에 대하여 읽기, 쓰기, 실행이 가능한지 등의 여부를 표시한다.
3. **참조 비트(reference bit, clock bit, used bit)**: 프레임이 읽기 또는 쓰기로 접근되면 `1`로 설정한다. 운영체제가 주기적으로 `0`으로 클리어해준다. 페이지 폴트가 발생하여 운영체제가 페이지 교체 정책에 따라 교체 대상을 선택할 때 사용한다. (최근에 참조된 것보다 참조되지 않은 페이지를 교체하는 것이 성능에 좋기 때문이다.)
4. 캐시 무효화 비트(caching disabled bit): 페이지가 캐싱될 수 있는지 여부를 가리킨다.
5. **더티 비트(dirty bit)**: 수정 비트(modified bit)라고도 한다. `1`이면 프레임이 교체될 때 그 내용을 디스크에 기록한다. `0`이면 클린(clean) 상태로 디스크에 기록될 필요가 없다.

### PTBR

프로세스는 각자 페이지 테이블을 가지며 이 페이지 테이블들은 DRAM에 저장되어 있다. 따라서 MMU가 주소 변환을 할 때 프로세스에 해당하는 페이지 테이블을 찾을 수 있어야 한다. 

**PTBR(Page Table Base Register)**는 현재 실행 중인 프로세스의 페이지 테이블이 저장된 메모리의 시작 주소를 저장한다. PTBR은 프로세스 제어 블록(PCB; Process Control Block)에 저장되어 있으며 문맥 교환의 대상이다. PCB는 CPU 내부에 있으므로, PTBR을 사용하면 상당히 빠르게 페이지 테이블을 찾을 수 있다.



## 페이징 성능 개선

페이징 시스템에서 고려해야할 성능 문제는 다음과 같다.

1. 가상 주소에서 물리 주소로 주소 변환하는 속도
2. 가상 메모리의 크기에 비례하는 페이지 테이블의 크기

다양한 방법을 통해 페이징 기법의 성능을 개선해보자. 첫번째는 TLB, 두번째는 다단계 페이지 테이블과 역 페이지 테이블로 해결해본다.

### TLB

페이지 테이블은 CPU 외부의 DRAM에 저장되어있다. 가상 메모리를 사용하지 않는 시스템에서는 메모리를 한 번만 접근해도 되었으나 가상 메모리 시스템에서는 메모리를 두 번 접근해야하므로 주소를 변환하는 속도가 느리다.

이 문제를 해결하기 위해 CPU 내부에 페이지 테이블의 엔트리 중 일부를 가지는 일종의 캐시로서 **TLB(Translation Lookaside Buffer)**를 둔다. MMU는 주소 변환을 하기 위해 TLB를 먼저 살핀 후 미스가 나면 DRAM의 페이지 테이블에서 검색한 후 찾은 엔트리를 TLB에 적재한다. TLB는 PTBR처럼 문맥 교환의 대상이다. 문맥 교환이 일어나면 TLB를 비운 후 PTBR을 바꾸므로 한동안 히트 rate가 낮아진다.

### 다단계 페이징

**다단계 페이징(multilevel paging)**은 페이지 테이블을 계층적으로 구성한다. 상위 페이지 테이블의 엔트리는 하위 페이지 테이블의 시작 주소를 저장한다. 마지막 페이지 테이블의 엔트리는 페이지 프레임의 번호를 저장한다. 2단계 페이지 테이블을 사용한다고 하자. PTBR은 외부 페이지 테이블의 시작 주소를 저장한다. 외부 페이지 테이블의 엔트리는 내부 페이지 테이블의 시작 주소를 저장한다. 내부 페이지 테이블의 엔트리는 페이지 프레임 번호를 저장한다.   

1. 가상 주소를 `<P1, P2, Offset>`으로 나눈다.
2. 외부 페이지 테이블에서 인덱스가 `P1`인 엔트리를 찾는다. 엔트리에는 내부 페이지 테이블의 시작 주소가 저장되어있다.
3. 내부 페이지 테이블에서 인덱스가 `P2`인 엔트리를 찾는다. 엔트리에는 페이지 프레임 번호가 저장되어있다,
4. 페이지 프레임 번호에 `Offset`을 더하여 물리 주소로 변환한다.

사용하지 않는 주소 공간에 대해서 외부 테이블 엔트리를 `NULL`로 유지하고 해당하는 내부 페이지 테이블을 생성하지 않으므로 메모리 낭비를 줄일 수 있다. 단, 페이지 테이블(메모리)에 접근하는 횟수가 늘어나 속도는 느려진다.

```
- 32비트 주소 체계
- 페이지의 크기는 4KB(2^12byte)
- 페이지 테이블 엔트리의 크기는 4byte

가상 주소의 P1, P2, Offset(바이트 오프셋)은 각각 몇 비트로 구성될까?
- Offset = 12비트		(페이지의 크기가 4KB=2^12byte이므로)
- P2 = 10비트			(하나의 내부 페이지 테이블은 하나의 프레임에 저장되므로 4KB(2^12byte)/4byte(2^2byte)=2^10byte)
- P1 = 10비트			(32비트 - Offset 크기 - P2 크기 = 32 - 12 - 10 = 10)

페이지 테이블의 크기는?
주소 공간의 크기를 2^32라고 하자. 2^20(2^32/4byte)개의 페이지 테이블 엔트리가 필요하다. 따라서 2^20*4byte=2^22byte가 필요하다.
```

### 역 페이지 테이블

전통적인 페이지 테이블은 가상 주소 공간의 각 페이지마다 하나의 엔트리를 유지한다. 따라서 페이지의 테이블의 크기는 가상 주소 공간의 크기에 비례한다. **역 페이지 테이블(inverted table)**은 물리 메모리의 각 페이지 프레임마다 하나의 엔트리를 유지한다. 이때 페이지 테이블의 크기는 물리 메모리의 크기에 비례하며 시스템을 통틀어 하나의 페이지 테이블만을 유지한다. 각 엔트리는 `(프로세스 번호, 페이지 번호)`를 포함한다.

가상 주소 공간이 물리 메모리의 크기보다 상당히 큰 경우 페이지 테이블의 크기를 크게 줄일 수 있다. 단, 가상 주소를 물리 주소로 변환하기 위해 전체 테이블을 탐색해야한다. TLB를 사용하여도 TLB 미스가 나면 전체 테이블 탐색이 필요하다. 가상 주소를 해싱한 값을 키로 가지고 같은 해시 값을 가지는 페이지를 체인으로 연결하는 해시 테이블을 사용하여 해결할 수 있다.



## 페이징 과정

페이징 기법을 사용하는 가상 메모리 시스템에서 프로세스를 실행하기까지의 과정은 다음과 같다.

1. 프로그램을 컴파일하여 실행 파일을 만든다. 이때 실행 파일의 주소는 가상 주소 0번지를 기준으로 한다.
2. 운영체제는 실행 파일을 실행하여 디스크의 SWAP 영역에 프로세스의 전체 수행 이미지를 만든다.
3. 메모리에 프로세스 주소 공간(힙, 스택)을 할당한 후, 라이브러리와 운영체제의 코드와 데이터를 매핑한다.
4. 원하는 페이지만 디스크의 SWAP 영역에서 읽어들여 메모리의 프레임에 넣고 실행한다.
5. 가상 주소를 참조하면 MMU가 페이지 테이블을 검색하고 valid 비트 검사를 한 후 물리 주소로 변환한다.
6. 물리 주소로 접근하여 데이터를 가져온다.



## 페이지 폴트

프로그램이 매핑되지 않은 주소를 참조하면, MMU는 페이지 테이블 엔트리의 valid 비트로 페이지가 유효하지 않다는 것(필요한 페이지가 메모리가 아니라 디스크의 SWAP 영역에 있음)을 파악하고 **페이지 폴트(page fault)** 예외를 발생시킨다.

페이지 폴트가 발생하면 페이지 폴트 핸들러가 실행된다.

1. CPU의 내부 회로는 디스크에 접근할 수 없으므로 CPU는 스스로 인터럽트를 걸어 운영체제로 JUMP한다.
2. 운영체제는 적재할 페이지를 SWAP 영역으로부터 읽어 메모리에서 빈 프레임에 넣는다. 이때 메모리에 빈 공간이 없다면 운영체제는 메모리 교체 정책에 따라 교체 대상 페이지(victim page)를 선택하여 디스크로 옮긴다.
3. 새롭게 적재한 프레임의 번호로 페이지 테이블 엔트리의 PFN을 갱신하고 valid 비트를 `1`로 설정한다.
4. CPU가 제어권을 넘겨받아 트랩을 발생시켰던 명령을 다시 실행한다.



## 페이지 교체 알고리즘

페이지 폴트가 발생하여 디스크의 SWAP 영역으로부터 페이지를 읽어 적재하려는데, 메모리에 빈 공간이 없다. 그렇다면 메모리에 있는 페이지를 SWAP 영역으로 내려 빈 공간을 만들어야한다. 이때 내보낼 페이지를 victim page라고 하며, victim page를 선택하기 위해 페이지 교체 알고리즘을 사용한다.

### OPT

**최적 페이지 교체 알고리즘(OPT; Optiomal Page Replacement)**는 앞으로 가장 사용하지 않을 페이지를 교체한다. 앞으로 페이지 폴트가 가장 적게 발생할 것이므로 이상적인 알고리즘이다. 그러나 운영체제는 페이지들이 미래에 언제 참조될지 알 수 없으므로 구현이 사실상 불가능하다.

### FIFO

**FIFO(First-In First-Out) 페이지 교체 알고리즘**은 메모리에 가장 먼저 적재된(적재된지 가장 오래된) 페이지를 교체한다. 운영체제는 페이지들을 연결 리스트로 구현하여 관리할 수 있다. 구현하기 간단하지만 자주 참조될 페이지를 내보내게 될 수도 있다.

### NRU

페이지 테이블 엔트리는 상태 비트로 reference bit와 modified bit를 유지한다. reference bit는 페이지가 최근의 클럭 틱 이후에 참조되었다는 것을 의미하며 modified bit는 페이지가 수정되었으며 디스크에 기록되어야할 필요가 있다는 것을 의미한다. 이 두 비트의 값에 따라 페이지들을 네 가지 클래스로 구분한다.

1. 클래스 0: reference bit 1, modified bit 1
2. 클래스 1: reference bit 0, modified bit 1
3. 클래스 2: reference bit 1, modified bit 0
4. 클래스 3: reference bit 0, modified bit 0

**NRU(Not Recently Used) 페이지 교체 알고리즘**은 모든 페이지를 순차적으로 검사하며 클래스 0에 해당하는 페이지부터 교체한다. 이해하기 쉽고 효율적으로 구현할 수 있으며, 좋은 성능을 제공한다. 클럭 알고리즘이라고도 한다.

### LRU

**LRU(Least Recently Used) 페이지 교체 알고리즘**은 참조된지 가장 오래된 페이지를 교체한다. 최근에 자주 접근된 페이지들은 가까운 미래에도 자주 접근될 확률이 높다는 관찰에서 비롯한다. 미래를 예측하는 OPT와 달리 과거를 기반으로 예측하므로 구현이 가능하다. 실제로 사용 가능한 알고리즘 중 하나로 성능이 좋다.

페이지 테이블 엔트리의 reference bit는 클럭 틱 마다 클리어되므로 LRU를 지원하는 하드웨어 시스템은 많지 않다. 소프트웨어적으로 LRU는 **NFU(Not Frequently Used) 알고리즘**을 통해 지원된다. NFU는 참조된 횟수가 가장 적은 페이지를 교체한다.



## 페이지 교체 정책

멀티 프로그래밍에서는 어떤 프로세스의 페이지를 교체할 것인지가 중요하다.

### 지역 페이지 교체 알고리즘

**지역(local) 페이지 교체 알고리즘**은 페이지 폴트를 발생시킨 페이지가 속한 프로세스의 페이지를 교체한다.

### 전역 페이지 교체 알고리즘

**지역(global) 페이지 교체 알고리즘**은 페이지 폴트를 발생시킨 페이지가 어느 프로세스에 속하는지에 관계없이 페이지를 선택하여 교체한다.

프로세스의 실행에 따라 필요한 페이지 수가 변하는 경우라면 전역 알고리즘의 성능이 좋다. 지역 알고리즘을 사용하면 비어있는 페이지 프레임이 있어도 페이지가 교체되어 스레싱이 일어날 수 있다.



## 메모리 할당 알고리즘

**메모리 할당 알고리즘(allocation algoritm)**은 멀티 프로그래밍 환경에서 각 프로세스에게 얼마만큼의 메모리를 할당할 것인지 결정한다.

1. 균등 할당(equal allocation): 모든 프로세스에게 동일한 크기의 메모리를 할당한다.
2. 비례 할당(proportional allocation): 프로세스의 크기에 비례하여 메모리를 할당한다.
3. 우선순위 할당(priority allocation): 지금 당장 실행될 프로세스에게 더 많은 메모리를 할당한다.



## 스레싱

**스레싱(thrashing)**은 가상 메모리 환경에서 프로세스에게 적절한 크기의 메모리를 할당하지 못하여 페이지 폴트가 자주 발생하고, 결과적으로 CPU 이용률이 감소하여 작업이 멈춘 것 같이 보이는 상태이다.

메모리에 올라간 프로세스의 수가 과도하게 많은 경우 프로세스는 원활히 수행될 정도의 메모리를 할당받지 못한다. 이때 페이지 폴트가 발생하면 페이지 교체를 위해 디스크 I/O가 발생하고 다른 프로세스로 문맥 교환된다. 그런데 다른 프로세스들 역시 동일한 이유에서 페이지 폴트를 발생시킨다면 CPU는 대부분의 시간을 페이지 교체에 사용하고 프로세스를 수행하지 못하게 된다.

프로세스의 수를 적절하게 조절하고 스레싱퍄의 발생을 방지하는 방법에는 워킹셋 알고리즘과 PFF가 있다.

### 워킹셋 알고리즘

지역성의 원리에 따라 프로세스는 현재 참조한 메모리와 가까운 메모리를 가까운 시일 내에 다시 참조할 가능성이 높다. **작업 집합(working set)은** 프로세스가 일정 시간 동안 자주 참조하는 페이지의 집합을 의미한다.

**워킹셋 알고리즘(working-set algorithm)**은 프로세스가 일정 시간 동안 원활히 수행될 수 있는 작업 집합을 구하는 메모리 관리 알고리즘이다. 작업 집합이 모두 메모리에 올라갈 수 있을 때에만 메모리를 할당하며, 그렇지 않다면 할당된 프레임을 모두 반납하고 주소 공간 전체를 SWAP OUT한다.

### PFF

**PFF(page fault frequency) 알고리즘**은 페이지 부재율(page fault rate)를 주기적으로 검사하여 프로세스에게 할당할 메모리를 동적으로 조절한다. 페이지 부재율이 상한값(upper bound)를 넘으면 추가적으로 메모리를 할당하며, 하한값(lower bound) 이하로 떨어지면 할당된 메모리를 줄인다.



## 공유 메모리 구현하기

가상 메모리에서는 서로 다른 프로세스가 페이지 테이블의 엔트리가 같은 프레임을 가리키도록 하여 데이터를 공유할 수 있다. UNIX의 **COPY-ON-WRITE** 전략은 다음과 같다. 공유하는 프레임을 가리키는 페이지 테이블 엔트리는 READ-ONLY(`r`:1, `w`: 0)으로 설정한다. 프로세스가 해당 프레임에 쓰기를 시도하면 trap이 발생하여 운영체제 커널로 JUMP한다. 운영체제는 새로운 메모리에 프레임을 복사하고 READ-WRITE(`r`:1, `w`: 0)으로 설정한다. 페이지 테이블 엔트리는 새로운 프레임을 가리키도록 하여, 결과적으로 두 프로세스는 서로 다른 프레임을 가리키게 된다. 명령이 재개되어 쓰기 요청이 허용되고 새로운 프레임에 쓰기 요청이 수행된다.



## 요구 세그먼테이션

**요구 세그먼테이션(segmentation) 기법**은 세그멘테이션 기법을 사용하는 가상 메모리 관리 기법이다. 프로세스의 주소 공간은 기능 단위(코드, 데이터, 스택 영역) 혹은 의미 있는 단위(함수)로 분할되는데 이것을 **세그먼트(segment)**라고 한다.

세그먼테이션에서는 가상 주소는 세그먼트를 구분하는 `세그먼트 번호`와 세그먼트의 시작 주소부터 해당 주소까지의 `거리`로 이루어진다. MMU는 **세그먼트 테이블(segment table)**을 사용하여 가상 주소를 물리 주소로 변환한다. 이때 주소를 변환하고 메모리 보호를 제공하는 방식이 base 레지스터와 limit 레지스터를 사용하는 방식과 동일하다. 세그먼트 테이블 엔트리는 세그먼트의 시작 주소를 나타내는 address와 세그먼트의 크기를 나타내는 limit으로 이루어진다. MMU는 가상 주소에 address의 값을 더하고 이 값이 address와 address에 limit을 더한 값 사이에 있는지 검사한다. 유효하지 않다면 **세그먼테이션 폴트(segmentation fault)**를 발생시킨다.

분할의 크기가 가변적이므로 외부 단편화가 발생할 수 있으며, 세그먼트를 가용 공간 어디에 배치할 것인지 결정해야한다.



## 페이지드 세그먼테이션

**페이지드-세그먼테이션(paged segmentation) 기법**에서는 프로세스 주소 공간이 여러 개의 의미 있는 세그먼트로 분할되고, 하나의 세그먼트가 다시 여러 개의 고정 크기의 페이지로 쪼개진다. 세그먼트의 크기는 페이지 크기의 배수이므로 외부 단편화를 해결할 수 있으며 세그먼트 단위의 공유와 보호가 가능하다.

가상 주소는 `세그먼트 번호`, `페이지 번호`, `오프셋`으로 구성된다. 주소 변환을 위한 테이블은 상위의 세그먼트 테이블과 하위의 페이지 테이블로 구성된다. 세그먼트 테이블의 엔트리는 페이지 테이블의 시작 주소를 저장하고, 페이지 테이블의 엔트리는 물리 메모리의 프레임 번호를 저장한다.

1. PTBR에 저장된 주소로 세그먼트 테이블에 접근한다.
2. 세그먼트 테이블에서 `세그먼트 번호`로 엔트리에 접근한다. 엔트리에는 페이지 테이블의 시작 주소로 저장되어있다.
3. 페이지 테이블에서 `페이지 번호`로 엔트리에 접근한다. 엔트리에는 페이지 프레임의 번호가 저장되어있다.
4. 페이지 프레임 번호에 오프셋을 더하여 물리 주소로 변환한다.



## 참고

- 운영체제 강의 필기
- 운영체제론(노삼혁, 이동희 전흥석, 최종무 공역) 3장 메모리 관리
- [리눅스 커널: 메모리 관리](https://wiki.kldp.org/Translations/html/The_Linux_Kernel-KLDP/tlk3.html)
- [geeksforgeeks - Page Table Entries in Page Table](https://www.geeksforgeeks.org/page-table-entries-in-page-table/)
- [OS는 할껀데 핵심만 합니다. 14편 가상 메모리 개요, 페이징](https://velog.io/@chappi/OS%EB%8A%94-%ED%95%A0%EA%BB%80%EB%8D%B0-%ED%95%B5%EC%8B%AC%EB%A7%8C-%ED%95%A9%EB%8B%88%EB%8B%A4.-14%ED%8E%B8-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B0%9C%EC%9A%94-%ED%8E%98%EC%9D%B4%EC%A7%95#%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC)
- [OS는 할껀데 핵심만 합니다. 15편 가상 메모리, 세그먼테이션, 세그먼테이션-페이징 혼용 기법](https://velog.io/@chappi/OS%EB%8A%94-%ED%95%A0%EA%BB%80%EB%8D%B0-%ED%95%B5%EC%8B%AC%EB%A7%8C-%ED%95%A9%EB%8B%88%EB%8B%A4.-15%ED%8E%B8-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%84%B8%EA%B7%B8%EB%A8%BC%ED%85%8C%EC%9D%B4%EC%85%98-%EC%84%B8%EA%B7%B8%EB%A8%BC%ED%85%8C%EC%9D%B4%EC%85%98-%ED%8E%98%EC%9D%B4%EC%A7%95-%ED%98%BC%EC%9A%A9-%EA%B8%B0%EB%B2%95)
- [OSTEP 18장 주소 변환의 원리](https://pages.cs.wisc.edu/~remzi/OSTEP/Korean/15-vm-mechanism.pdf)
- [OSTEP 21장 페이징: 개요](https://pages.cs.wisc.edu/~remzi/OSTEP/Korean/18-vm-paging.pdf)
- 운영체제와 정보기술의 원리 - 7장 메모리 관리, 8장 가상 메모리 



## 스터디

### 가상 메모리를 사용했을 때의 장점은 무엇인가?

가상 메모리는 무한한 크기의 주소 공간이라는 환상을 제공하여 프로세스가 실제 물리 메모리의 크기에 제약을 받지 않을 수 있다. 직접 주소를 사용할 경우 잘못된 접근으로 프로세스가 다운될 수 있는데, 가상 주소를 사용하여 프로세스의 독립적인 주소 공간을 보호할 수 있다. 페이지 테이블 엔트리의 protection 비트로 페이지별로 보호 기능을 제공한다. 또한 프로세스의 페이지 테이블의 엔트리가 같은 프레임을 가리키도록 하여 공유 메모리를 사용할 수 있다.
